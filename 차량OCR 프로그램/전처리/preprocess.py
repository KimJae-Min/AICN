#!/usr/bin/env python3
import json, random, csv
from pathlib import Path
from PIL import Image
from tqdm import tqdm

# â”€â”€â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PROJECT_ROOT       = Path(__file__).resolve().parent.parent
RAW_FULL_ANN_DIR   = PROJECT_ROOT/"raw/full_vehicle/annotations"
RAW_FULL_IMG_ROOT  = PROJECT_ROOT/"raw/full_vehicle/images"
RAW_CROP_DIR       = PROJECT_ROOT/"raw/cropped_plate"
OUT_DET            = PROJECT_ROOT/"datasets/detection"
OUT_REC            = PROJECT_ROOT/"datasets/recognition"
DATA_DIR           = PROJECT_ROOT/"data"
VAL_RATIO          = 0.2
CLASS_ID           = 0
CLASS_NAMES        = ["license_plate"]

# â”€â”€â”€â”€â”€ 1) ì´ë¯¸ì§€ ì¸ë±ìŠ¤ êµ¬ì¶• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("â³ Indexing images under", RAW_FULL_IMG_ROOT)
IMG_IDX = {p.name: p for p in RAW_FULL_IMG_ROOT.rglob("*") if p.is_file()}
print(f"ğŸ“‚ Found {len(IMG_IDX)} images")

def find_img(filename: str) -> Path:
    """
    1) ì •í™•íˆ ë§¤ì¹­
    2) ì ‘ë¯¸ì‚¬ ë§¤ì¹­ (endswith)
    3) ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹­
    """
    # 1) exact
    if filename in IMG_IDX:
        return IMG_IDX[filename]
    # 2) suffix
    for name, path in IMG_IDX.items():
        if name.endswith(filename):
            return path
    # 3) substring
    for name, path in IMG_IDX.items():
        if filename in name:
            return path
    raise FileNotFoundError(f"{filename} not found")

# â”€â”€â”€â”€â”€ 2) ì „ì²´ ì–´ë…¸í…Œì´ì…˜ ë¡œë“œ & ì…”í”Œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
all_ann = []
print("â³ Loading annotation entriesâ€¦")
for jf in tqdm(list(RAW_FULL_ANN_DIR.rglob("*.json")), desc="JSON files"):
    try:
        data = json.loads(jf.read_text(encoding="utf-8"))
    except:
        continue
    if isinstance(data, list):
        all_ann.extend(data)
    elif isinstance(data, dict) and "annotations" in data:
        all_ann.extend(data["annotations"])
    else:
        all_ann.append(data)
print(f"â–¶ Total annotation entries: {len(all_ann):,}")

random.shuffle(all_ann)
n_val = int(len(all_ann) * VAL_RATIO)
train_entries, val_entries = all_ann[n_val:], all_ann[:n_val]
print(f"â–¶ Train/Val split: {len(train_entries):,}/{len(val_entries):,}")

# â”€â”€â”€â”€â”€ 3) Detection ì „ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
(OUT_DET / "labels" / "train").mkdir(parents=True, exist_ok=True)
(OUT_DET / "labels" / "val"  ).mkdir(parents=True, exist_ok=True)
OUT_DET.mkdir(parents=True, exist_ok=True)

def yolo_line(bbox, w, h, cid=0):
    (x1,y1),(x2,y2) = bbox
    xc = ((x1+x2)/2)/w; yc = ((y1+y2)/2)/h
    bw = (x2-x1)/w; bh = (y2-y1)/h
    return f"{cid} {xc:.6f} {yc:.6f} {bw:.6f} {bh:.6f}"

def make_detection(entries, subset):
    seen = set()
    list_f = open(OUT_DET/f"{subset}.txt","w")
    for e in tqdm(entries, desc=f"Detectâ†’{subset}", mininterval=1.0):
        fn = Path(e["imagePath"]).name
        if fn in seen:
            continue
        try:
            img_p = find_img(fn)
        except FileNotFoundError:
            continue
        seen.add(fn)

        bbox = e.get("plate",{}).get("bbox")
        if not bbox:
            continue

        w, h = Image.open(img_p).size
        line = yolo_line(bbox, w, h, CLASS_ID)
        # ë ˆì´ë¸” íŒŒì¼ ì“°ê¸°
        lbl_file = OUT_DET/"labels"/subset/f"{img_p.stem}.txt"
        lbl_file.write_text(line + "\n", encoding="utf-8")
        # ë¦¬ìŠ¤íŠ¸ì— ì´ë¯¸ì§€ ê²½ë¡œ ì¶”ê°€
        list_f.write(str(img_p.resolve()) + "\n")

    list_f.close()
    print(f"âœ… {subset} detection done: {len(seen):,} images")

make_detection(train_entries, "train")
make_detection(val_entries,   "val")

# custom_det.yaml ìƒì„±
DATA_DIR.mkdir(parents=True, exist_ok=True)
yaml = DATA_DIR/"custom_det.yaml"
yaml.write_text(
    f"train: { (OUT_DET/'train.txt').resolve() }\n"
    f"val:   { (OUT_DET/'val.txt').resolve() }\n\n"
    f"nc: {len(CLASS_NAMES)}\nnames: {CLASS_NAMES}\n"
)
print("âœ… Detection config written to", yaml)

# â”€â”€â”€â”€â”€ 4) Recognition ì „ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
plate_jsons = list(RAW_CROP_DIR.rglob("plate.json"))
if not plate_jsons:
    print("âš ï¸ No plate.json found under", RAW_CROP_DIR, "â†’ Skipping recognition")
else:
    (OUT_REC / "labels").mkdir(parents=True, exist_ok=True)
    for pj in plate_jsons:
        subset = pj.parent.name  # ì˜ˆ: 'train' ë˜ëŠ” 'val'
        img_root = pj.parent/"images"
        out_csv = OUT_REC/"labels"/f"{subset}.csv"
        rows = [["image","plate"]]

        annos = json.loads(pj.read_text(encoding="utf-8"))
        for p in tqdm(annos, desc=f"Recogâ†’{subset}", mininterval=1.0):
            fn  = p.get("imagePath")
            txt = p.get("value","")
            ip  = img_root/fn
            if ip.exists():
                rows.append([str(ip.resolve()), txt])

        with open(out_csv, "w", newline="", encoding="utf-8") as cf:
            writer = csv.writer(cf)
            writer.writerows(rows)
        print(f"âœ… {subset} recognition CSV: {len(rows)-1:,} entries")

print("ğŸ‰ Preprocessing complete.")
